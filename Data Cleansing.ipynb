{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweet_df = pd.read_csv('HOT_dataset_modified.csv',index_col=None, header=None, engine='python')\n",
    "raw_tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(raw_tweet_df, columns=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.rename(index=str, columns={0: 'score', 1: 'text'})\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.dropna(inplace = True)\n",
    "tweet_df.shape\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the usernames from tweets\n",
    "import re\n",
    "\n",
    "remove_usr_pattern = r'@[\\w]+'\n",
    "tweet_df.replace(to_replace = remove_usr_pattern, value = \"\", inplace = True, regex = True)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any links present in the tweets\n",
    "\n",
    "url_links_pattern = r'https?://[A-Za-z0-9./]+'\n",
    "tweet_df.replace(to_replace = url_links_pattern, value = \"\", inplace = True, regex = True)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing '\\n' in data with a space\n",
    "\n",
    "tweet_df.replace(to_replace = r'\\\\n', value = ' ', inplace = True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smileys in the tweeets are represented in a format like \\x6\\xf.....\n",
    "# using the pattern to remove these smiley representations\n",
    "\n",
    "tweet_df.replace(to_replace = r'\\\\[\\w]+', value = ' ', inplace = True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing numbers, puntuations.. only alphabets remain in the tweet text.\n",
    "\n",
    "tweet_df.replace(to_replace = r'[^a-zA-Z]',value = ' ', inplace = True, regex = True)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing multiple spaces together with a single space\n",
    "\n",
    "tweet_df.replace(to_replace = r'\\s+',value = ' ', inplace = True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the rows which have only a space ' ' in their text. data cleaning steps removed everything from those tweets.\n",
    "remove_rows_index = []\n",
    "for idx in tweet_df.index:\n",
    "    if tweet_df['text'][idx]== ' ':\n",
    "        remove_rows_index.append(idx)\n",
    "        \n",
    "tweet_df.drop(tweet_df.index[remove_rows_index], inplace = True)\n",
    "\n",
    "tweet_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.reset_index(inplace = True, drop = True)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of the stopwords in hinglish\n",
    "file_path = 'data/stopwords_hinglish.txt'\n",
    "with open(file_path, 'r') as f:\n",
    "    line = f.readlines()\n",
    "    stopwords_hinglish = [word.strip() for word in line ]\n",
    "    \n",
    "# I also appended some words in the stopword list which I felt did not add any value to the text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the tweets and remove stop words\n",
    "\n",
    "tok = WordPunctTokenizer()\n",
    "tweets = tweet_df.text.copy()\n",
    "score = tweet_df.score.copy()\n",
    "\n",
    "clean_tweets = []\n",
    "word_count = {}\n",
    "\n",
    "for t in tweets:\n",
    "    lower_case = t.lower()\n",
    "    tokens = tok.tokenize(lower_case)\n",
    "    words = []\n",
    "    for token in tokens:\n",
    "        if token in stopwords_hinglish:\n",
    "            pass\n",
    "        else:\n",
    "            words.append(token)\n",
    "    \n",
    "    clean_tweets.append((\" \".join(words)).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new data frame with clean tweets\n",
    "\n",
    "clean_tweets_df = pd.DataFrame(clean_tweets, columns=['text'])\n",
    "clean_tweets_df['score'] = score\n",
    "clean_tweets_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the score (label) of each tweet to integer from float \n",
    "clean_tweets_df['score'] = clean_tweets_df['score'].apply(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the class distribution of tweets(0 - Benign, 1 - Hate inducing, 2 - Abusive)\n",
    "classCountDf = clean_tweets_df.groupby(\"score\",as_index = False)[\"text\"].count()\n",
    "classCountDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of rows which are empty strings\n",
    "cnt = 0\n",
    "for idx in clean_tweets_df.index:\n",
    "    if clean_tweets_df['text'][idx] == \"\":\n",
    "        cnt+=1\n",
    "print(cnt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the empty rows from dataframe\n",
    "empty_rows_index = []\n",
    "for idx in clean_tweets_df.index:\n",
    "    if clean_tweets_df['text'][idx] == \"\":\n",
    "        empty_rows_index.append(idx)\n",
    "        \n",
    "clean_tweets_df.drop(clean_tweets_df.index[empty_rows_index], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the class distribution of the the data\n",
    "classCountDf = clean_tweets_df.groupby(\"score\",as_index = False)[\"text\"].count()\n",
    "classCountDf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df.to_csv('tweets_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-practice",
   "language": "python",
   "name": "dl-practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
